{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import json\n",
    "from data_gen.data_gen import PointInferenceDatasetGenerator, ClassInferenceDatasetGenerator\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Inference Data 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_img_path = './dataset/test/img'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Inference Data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_img_list = os.listdir(inference_img_path)\n",
    "inference_img_list = sorted(inference_img_list)\n",
    "inference_img_list = [os.path.join(inference_img_path, img) for img in inference_img_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'cropped_image/inference'\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Dataloader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = PointInferenceDatasetGenerator(inference_img_list)\n",
    "inference_dataloader = inference_dataset.dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 학습된 Point Prediction Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'resnet18'\n",
    "vision_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = vision_model.fc.in_features\n",
    "vision_model.fc = nn.Linear(num_ftrs, 8)\n",
    "vision_model.load_state_dict(torch.load('result/Best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Point 예측에 대한 Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n"
     ]
    }
   ],
   "source": [
    "print('Prediction')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictions = []\n",
    "vision_model.to(device)\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in inference_dataloader['test']:\n",
    "        images, width, height, original_image, fname = data['image'].float().to(device), data['width'].float(), data['height'].float(), data['original_image'].float(), data['fname']\n",
    "        images = images.to(device)  \n",
    "        vision_model.eval()  \n",
    "        yhat = vision_model(images)  \n",
    "        pred = yhat.cpu().numpy()\n",
    "        horizen_min = min(pred[0][0], pred[0][2], pred[0][4], pred[0][6])\n",
    "        horizen_max = max(pred[0][0], pred[0][2], pred[0][4], pred[0][6])\n",
    "        vertical_min = min(pred[0][1], pred[0][3], pred[0][5], pred[0][7])\n",
    "        vertical_max = max(pred[0][1], pred[0][3], pred[0][5], pred[0][7])\n",
    "        horizen_min = int(horizen_min / 448 * height)\n",
    "        horizen_max = int(horizen_max / 448 * height)\n",
    "        vertical_min = int(vertical_min / 224 * width)\n",
    "        vertical_max = int(vertical_max / 224 * width)\n",
    "        cropped_image = np.array(original_image)[0, :, :, :][vertical_min:vertical_max, horizen_min:horizen_max, :]\n",
    "        save_fname = os.path.join(save_path, fname[0])\n",
    "        cv2.imwrite(save_fname, cropped_image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Dataloader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = ClassInferenceDatasetGenerator(inference_img_list)\n",
    "inference_dataloader = inference_dataset.dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 학습된 Class Prediction Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'resnet18'\n",
    "vision_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = vision_model.fc.in_features\n",
    "uni_label = ['1996_n', '2004_n', '2006_eu', '2006_n', '2006_us', '2019_n', '2019_r', 'bike', 'echo']\n",
    "vision_model.fc = nn.Linear(num_ftrs, len(uni_label))\n",
    "vision_model.load_state_dict(torch.load('result/Classification_Best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Prediction\n"
     ]
    }
   ],
   "source": [
    "print('Test Prediction')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictions = []\n",
    "vision_model.to(device)\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in inference_dataloader['test']:\n",
    "        images = data['image'].float().to(device)\n",
    "        images = images.to(device)  \n",
    "        vision_model.eval()  \n",
    "        yhat = vision_model(images)  \n",
    "        pred = yhat.argmax(dim=1, keepdim = False)\n",
    "        pred = list(pred.cpu().numpy())\n",
    "        predictions = predictions + pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [uni_label[i] for i in predictions]\n",
    "result = pd.DataFrame({'File': inference_img_list, 'Prediction': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/test/img/01가2636.JPG</td>\n",
       "      <td>2006_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/test/img/01고9570.JPG</td>\n",
       "      <td>2006_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/test/img/01구2337.jpg</td>\n",
       "      <td>2004_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/test/img/01라0185.jpg</td>\n",
       "      <td>1996_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/test/img/01라0553.jpg</td>\n",
       "      <td>2006_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>./dataset/test/img/전북32바7467.jpg</td>\n",
       "      <td>echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>./dataset/test/img/전북32바7553.jpg</td>\n",
       "      <td>echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>./dataset/test/img/전북32바7595.jpg</td>\n",
       "      <td>echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>./dataset/test/img/전북82배1120.JPG</td>\n",
       "      <td>echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>./dataset/test/img/전북82배1184.jpg</td>\n",
       "      <td>echo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File Prediction\n",
       "0     ./dataset/test/img/01가2636.JPG     2006_n\n",
       "1     ./dataset/test/img/01고9570.JPG     2006_n\n",
       "2     ./dataset/test/img/01구2337.jpg     2004_n\n",
       "3     ./dataset/test/img/01라0185.jpg     1996_n\n",
       "4     ./dataset/test/img/01라0553.jpg     2006_n\n",
       "..                               ...        ...\n",
       "58  ./dataset/test/img/전북32바7467.jpg       echo\n",
       "59  ./dataset/test/img/전북32바7553.jpg       echo\n",
       "60  ./dataset/test/img/전북32바7595.jpg       echo\n",
       "61  ./dataset/test/img/전북82배1120.JPG       echo\n",
       "62  ./dataset/test/img/전북82배1184.jpg       echo\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8786e27bd1086ac4d9d40cc5555f877076005eb73afcfe8ecd44164236edd6aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('vision_machine')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
